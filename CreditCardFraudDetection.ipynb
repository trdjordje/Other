{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Credit card fraud detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('precision', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.35981</td>\n",
       "      <td>-0.07278</td>\n",
       "      <td>2.53635</td>\n",
       "      <td>1.37816</td>\n",
       "      <td>-0.33832</td>\n",
       "      <td>0.46239</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.09870</td>\n",
       "      <td>0.36379</td>\n",
       "      <td>0.09079</td>\n",
       "      <td>-0.55160</td>\n",
       "      <td>-0.61780</td>\n",
       "      <td>-0.99139</td>\n",
       "      <td>-0.31117</td>\n",
       "      <td>1.46818</td>\n",
       "      <td>-0.47040</td>\n",
       "      <td>0.20797</td>\n",
       "      <td>0.02579</td>\n",
       "      <td>0.40399</td>\n",
       "      <td>0.25141</td>\n",
       "      <td>-0.01831</td>\n",
       "      <td>0.27784</td>\n",
       "      <td>-0.11047</td>\n",
       "      <td>0.06693</td>\n",
       "      <td>0.12854</td>\n",
       "      <td>-0.18911</td>\n",
       "      <td>0.13356</td>\n",
       "      <td>-0.02105</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.19186</td>\n",
       "      <td>0.26615</td>\n",
       "      <td>0.16648</td>\n",
       "      <td>0.44815</td>\n",
       "      <td>0.06002</td>\n",
       "      <td>-0.08236</td>\n",
       "      <td>-0.07880</td>\n",
       "      <td>0.08510</td>\n",
       "      <td>-0.25543</td>\n",
       "      <td>-0.16697</td>\n",
       "      <td>1.61273</td>\n",
       "      <td>1.06524</td>\n",
       "      <td>0.48910</td>\n",
       "      <td>-0.14377</td>\n",
       "      <td>0.63556</td>\n",
       "      <td>0.46392</td>\n",
       "      <td>-0.11480</td>\n",
       "      <td>-0.18336</td>\n",
       "      <td>-0.14578</td>\n",
       "      <td>-0.06908</td>\n",
       "      <td>-0.22578</td>\n",
       "      <td>-0.63867</td>\n",
       "      <td>0.10129</td>\n",
       "      <td>-0.33985</td>\n",
       "      <td>0.16717</td>\n",
       "      <td>0.12589</td>\n",
       "      <td>-0.00898</td>\n",
       "      <td>0.01472</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.35835</td>\n",
       "      <td>-1.34016</td>\n",
       "      <td>1.77321</td>\n",
       "      <td>0.37978</td>\n",
       "      <td>-0.50320</td>\n",
       "      <td>1.80050</td>\n",
       "      <td>0.79146</td>\n",
       "      <td>0.24768</td>\n",
       "      <td>-1.51465</td>\n",
       "      <td>0.20764</td>\n",
       "      <td>0.62450</td>\n",
       "      <td>0.06608</td>\n",
       "      <td>0.71729</td>\n",
       "      <td>-0.16595</td>\n",
       "      <td>2.34586</td>\n",
       "      <td>-2.89008</td>\n",
       "      <td>1.10997</td>\n",
       "      <td>-0.12136</td>\n",
       "      <td>-2.26186</td>\n",
       "      <td>0.52498</td>\n",
       "      <td>0.24800</td>\n",
       "      <td>0.77168</td>\n",
       "      <td>0.90941</td>\n",
       "      <td>-0.68928</td>\n",
       "      <td>-0.32764</td>\n",
       "      <td>-0.13910</td>\n",
       "      <td>-0.05535</td>\n",
       "      <td>-0.05975</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.96627</td>\n",
       "      <td>-0.18523</td>\n",
       "      <td>1.79299</td>\n",
       "      <td>-0.86329</td>\n",
       "      <td>-0.01031</td>\n",
       "      <td>1.24720</td>\n",
       "      <td>0.23761</td>\n",
       "      <td>0.37744</td>\n",
       "      <td>-1.38702</td>\n",
       "      <td>-0.05495</td>\n",
       "      <td>-0.22649</td>\n",
       "      <td>0.17823</td>\n",
       "      <td>0.50776</td>\n",
       "      <td>-0.28792</td>\n",
       "      <td>-0.63142</td>\n",
       "      <td>-1.05965</td>\n",
       "      <td>-0.68409</td>\n",
       "      <td>1.96578</td>\n",
       "      <td>-1.23262</td>\n",
       "      <td>-0.20804</td>\n",
       "      <td>-0.10830</td>\n",
       "      <td>0.00527</td>\n",
       "      <td>-0.19032</td>\n",
       "      <td>-1.17558</td>\n",
       "      <td>0.64738</td>\n",
       "      <td>-0.22193</td>\n",
       "      <td>0.06272</td>\n",
       "      <td>0.06146</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.15823</td>\n",
       "      <td>0.87774</td>\n",
       "      <td>1.54872</td>\n",
       "      <td>0.40303</td>\n",
       "      <td>-0.40719</td>\n",
       "      <td>0.09592</td>\n",
       "      <td>0.59294</td>\n",
       "      <td>-0.27053</td>\n",
       "      <td>0.81774</td>\n",
       "      <td>0.75307</td>\n",
       "      <td>-0.82284</td>\n",
       "      <td>0.53820</td>\n",
       "      <td>1.34585</td>\n",
       "      <td>-1.11967</td>\n",
       "      <td>0.17512</td>\n",
       "      <td>-0.45145</td>\n",
       "      <td>-0.23703</td>\n",
       "      <td>-0.03819</td>\n",
       "      <td>0.80349</td>\n",
       "      <td>0.40854</td>\n",
       "      <td>-0.00943</td>\n",
       "      <td>0.79828</td>\n",
       "      <td>-0.13746</td>\n",
       "      <td>0.14127</td>\n",
       "      <td>-0.20601</td>\n",
       "      <td>0.50229</td>\n",
       "      <td>0.21942</td>\n",
       "      <td>0.21515</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time       V1       V2       V3       V4       V5       V6       V7  \\\n",
       "0   0.0 -1.35981 -0.07278  2.53635  1.37816 -0.33832  0.46239  0.23960   \n",
       "1   0.0  1.19186  0.26615  0.16648  0.44815  0.06002 -0.08236 -0.07880   \n",
       "2   1.0 -1.35835 -1.34016  1.77321  0.37978 -0.50320  1.80050  0.79146   \n",
       "3   1.0 -0.96627 -0.18523  1.79299 -0.86329 -0.01031  1.24720  0.23761   \n",
       "4   2.0 -1.15823  0.87774  1.54872  0.40303 -0.40719  0.09592  0.59294   \n",
       "\n",
       "        V8       V9      V10      V11      V12      V13      V14      V15  \\\n",
       "0  0.09870  0.36379  0.09079 -0.55160 -0.61780 -0.99139 -0.31117  1.46818   \n",
       "1  0.08510 -0.25543 -0.16697  1.61273  1.06524  0.48910 -0.14377  0.63556   \n",
       "2  0.24768 -1.51465  0.20764  0.62450  0.06608  0.71729 -0.16595  2.34586   \n",
       "3  0.37744 -1.38702 -0.05495 -0.22649  0.17823  0.50776 -0.28792 -0.63142   \n",
       "4 -0.27053  0.81774  0.75307 -0.82284  0.53820  1.34585 -1.11967  0.17512   \n",
       "\n",
       "       V16      V17      V18      V19      V20      V21      V22      V23  \\\n",
       "0 -0.47040  0.20797  0.02579  0.40399  0.25141 -0.01831  0.27784 -0.11047   \n",
       "1  0.46392 -0.11480 -0.18336 -0.14578 -0.06908 -0.22578 -0.63867  0.10129   \n",
       "2 -2.89008  1.10997 -0.12136 -2.26186  0.52498  0.24800  0.77168  0.90941   \n",
       "3 -1.05965 -0.68409  1.96578 -1.23262 -0.20804 -0.10830  0.00527 -0.19032   \n",
       "4 -0.45145 -0.23703 -0.03819  0.80349  0.40854 -0.00943  0.79828 -0.13746   \n",
       "\n",
       "       V24      V25      V26      V27      V28  Amount  Class  \n",
       "0  0.06693  0.12854 -0.18911  0.13356 -0.02105  149.62      0  \n",
       "1 -0.33985  0.16717  0.12589 -0.00898  0.01472    2.69      0  \n",
       "2 -0.68928 -0.32764 -0.13910 -0.05535 -0.05975  378.66      0  \n",
       "3 -1.17558  0.64738 -0.22193  0.06272  0.06146  123.50      0  \n",
       "4  0.14127 -0.20601  0.50229  0.21942  0.21515   69.99      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.85958</td>\n",
       "      <td>88.34962</td>\n",
       "      <td>0.00173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.14595</td>\n",
       "      <td>250.12011</td>\n",
       "      <td>0.04153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.50000</td>\n",
       "      <td>5.60000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.00000</td>\n",
       "      <td>22.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.50000</td>\n",
       "      <td>77.16500</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.00000</td>\n",
       "      <td>25691.16000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Time        Amount         Class\n",
       "count  284807.00000  284807.00000  284807.00000\n",
       "mean    94813.85958      88.34962       0.00173\n",
       "std     47488.14595     250.12011       0.04153\n",
       "min         0.00000       0.00000       0.00000\n",
       "25%     54201.50000       5.60000       0.00000\n",
       "50%     84692.00000      22.00000       0.00000\n",
       "75%    139320.50000      77.16500       0.00000\n",
       "max    172792.00000   25691.16000       1.00000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['Time', 'Amount', 'Class']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['Time', 'Amount'])\n",
    "\n",
    "y = pd.DataFrame(data['Class'])\n",
    "X = data.drop(columns=['Class'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimenzije skupa podataka za trening i test: (213605, 1) | (71202, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimenzije skupa podataka za trening i test: {} | {}\".format(y_train.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-02 22:56:13.445584\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start proces 2020-12-01 11:21:24.725103\n",
      "End proces 2020-12-01 11:25:37.187303\n"
     ]
    }
   ],
   "source": [
    "print('Start proces {}'.format(datetime.now()))\n",
    "\n",
    "clf = xgb.XGBClassifier(tree_method='hist', seed=1)\n",
    "\n",
    "params = {'learning_rate':[0.01], \n",
    "          'n_estimators':[1000], \n",
    "          'min_child_weight':[1, 3, 5],\n",
    "          'scale_pos_weight':[1, 3, 5, 10]}\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=33)\n",
    "\n",
    "gsearch = GridSearchCV(clf, param_grid=params, cv=kf, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "gs_fit = gsearch.fit(X_train, y_train)\n",
    "\n",
    "print('End proces {}'.format(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.87504</td>\n",
       "      <td>{'learning_rate': 0.01, 'min_child_weight': 3, 'n_estimators': 1000, 'scale_pos_weight': 10}</td>\n",
       "      <td>0.98358</td>\n",
       "      <td>0.00256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.62153</td>\n",
       "      <td>{'learning_rate': 0.01, 'min_child_weight': 5, 'n_estimators': 1000, 'scale_pos_weight': 10}</td>\n",
       "      <td>0.98334</td>\n",
       "      <td>0.00311</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.46497</td>\n",
       "      <td>{'learning_rate': 0.01, 'min_child_weight': 1, 'n_estimators': 1000, 'scale_pos_weight': 1}</td>\n",
       "      <td>0.98319</td>\n",
       "      <td>0.00399</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.25311</td>\n",
       "      <td>{'learning_rate': 0.01, 'min_child_weight': 5, 'n_estimators': 1000, 'scale_pos_weight': 5}</td>\n",
       "      <td>0.98296</td>\n",
       "      <td>0.00342</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.97758</td>\n",
       "      <td>{'learning_rate': 0.01, 'min_child_weight': 3, 'n_estimators': 1000, 'scale_pos_weight': 3}</td>\n",
       "      <td>0.98269</td>\n",
       "      <td>0.00357</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.89194</td>\n",
       "      <td>{'learning_rate': 0.01, 'min_child_weight': 5, 'n_estimators': 1000, 'scale_pos_weight': 1}</td>\n",
       "      <td>0.98237</td>\n",
       "      <td>0.00243</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.15301</td>\n",
       "      <td>{'learning_rate': 0.01, 'min_child_weight': 1, 'n_estimators': 1000, 'scale_pos_weight': 10}</td>\n",
       "      <td>0.98195</td>\n",
       "      <td>0.00331</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.30074</td>\n",
       "      <td>{'learning_rate': 0.01, 'min_child_weight': 3, 'n_estimators': 1000, 'scale_pos_weight': 5}</td>\n",
       "      <td>0.98188</td>\n",
       "      <td>0.00347</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.79082</td>\n",
       "      <td>{'learning_rate': 0.01, 'min_child_weight': 5, 'n_estimators': 1000, 'scale_pos_weight': 3}</td>\n",
       "      <td>0.98135</td>\n",
       "      <td>0.00255</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.17650</td>\n",
       "      <td>{'learning_rate': 0.01, 'min_child_weight': 3, 'n_estimators': 1000, 'scale_pos_weight': 1}</td>\n",
       "      <td>0.98084</td>\n",
       "      <td>0.00267</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.59329</td>\n",
       "      <td>{'learning_rate': 0.01, 'min_child_weight': 1, 'n_estimators': 1000, 'scale_pos_weight': 5}</td>\n",
       "      <td>0.98068</td>\n",
       "      <td>0.00398</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.29521</td>\n",
       "      <td>{'learning_rate': 0.01, 'min_child_weight': 1, 'n_estimators': 1000, 'scale_pos_weight': 3}</td>\n",
       "      <td>0.98048</td>\n",
       "      <td>0.00243</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_score_time  \\\n",
       "7           3.87504   \n",
       "11          1.62153   \n",
       "0           2.46497   \n",
       "10          2.25311   \n",
       "5           2.97758   \n",
       "8           1.89194   \n",
       "3           4.15301   \n",
       "6           3.30074   \n",
       "9           2.79082   \n",
       "4           2.17650   \n",
       "2           3.59329   \n",
       "1           3.29521   \n",
       "\n",
       "                                                                                          params  \\\n",
       "7   {'learning_rate': 0.01, 'min_child_weight': 3, 'n_estimators': 1000, 'scale_pos_weight': 10}   \n",
       "11  {'learning_rate': 0.01, 'min_child_weight': 5, 'n_estimators': 1000, 'scale_pos_weight': 10}   \n",
       "0    {'learning_rate': 0.01, 'min_child_weight': 1, 'n_estimators': 1000, 'scale_pos_weight': 1}   \n",
       "10   {'learning_rate': 0.01, 'min_child_weight': 5, 'n_estimators': 1000, 'scale_pos_weight': 5}   \n",
       "5    {'learning_rate': 0.01, 'min_child_weight': 3, 'n_estimators': 1000, 'scale_pos_weight': 3}   \n",
       "8    {'learning_rate': 0.01, 'min_child_weight': 5, 'n_estimators': 1000, 'scale_pos_weight': 1}   \n",
       "3   {'learning_rate': 0.01, 'min_child_weight': 1, 'n_estimators': 1000, 'scale_pos_weight': 10}   \n",
       "6    {'learning_rate': 0.01, 'min_child_weight': 3, 'n_estimators': 1000, 'scale_pos_weight': 5}   \n",
       "9    {'learning_rate': 0.01, 'min_child_weight': 5, 'n_estimators': 1000, 'scale_pos_weight': 3}   \n",
       "4    {'learning_rate': 0.01, 'min_child_weight': 3, 'n_estimators': 1000, 'scale_pos_weight': 1}   \n",
       "2    {'learning_rate': 0.01, 'min_child_weight': 1, 'n_estimators': 1000, 'scale_pos_weight': 5}   \n",
       "1    {'learning_rate': 0.01, 'min_child_weight': 1, 'n_estimators': 1000, 'scale_pos_weight': 3}   \n",
       "\n",
       "    mean_test_score  std_test_score  rank_test_score  \n",
       "7           0.98358         0.00256                1  \n",
       "11          0.98334         0.00311                2  \n",
       "0           0.98319         0.00399                3  \n",
       "10          0.98296         0.00342                4  \n",
       "5           0.98269         0.00357                5  \n",
       "8           0.98237         0.00243                6  \n",
       "3           0.98195         0.00331                7  \n",
       "6           0.98188         0.00347                8  \n",
       "9           0.98135         0.00255                9  \n",
       "4           0.98084         0.00267               10  \n",
       "2           0.98068         0.00398               11  \n",
       "1           0.98048         0.00243               12  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs_fit.cv_results_)[['mean_score_time', 'params', 'mean_test_score', 'std_test_score', 'rank_test_score']].sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start proces 2020-12-01 20:15:04.146595\n",
      "End proces 2020-12-01 20:17:32.859992\n"
     ]
    }
   ],
   "source": [
    "print('Start proces {}'.format(datetime.now()))\n",
    "\n",
    "clf = xgb.XGBClassifier(tree_method='hist', seed=1)\n",
    "\n",
    "params = {'learning_rate':[0.01], \n",
    "          'n_estimators':[1000], \n",
    "          'min_child_weight':[3],\n",
    "          'scale_pos_weight':[10, 15, 20, 25, 30, 35]}\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=33)\n",
    "\n",
    "gsearch = GridSearchCV(clf, param_grid=params, cv=kf, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "gs_fit_1 = gsearch.fit(X_train, y_train)\n",
    "\n",
    "print('End proces {}'.format(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.51106</td>\n",
       "      <td>{'learning_rate': 0.01, 'min_child_weight': 3, 'n_estimators': 1000, 'scale_pos_weight': 10}</td>\n",
       "      <td>0.98358</td>\n",
       "      <td>0.00256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.94457</td>\n",
       "      <td>{'learning_rate': 0.01, 'min_child_weight': 3, 'n_estimators': 1000, 'scale_pos_weight': 25}</td>\n",
       "      <td>0.98357</td>\n",
       "      <td>0.00354</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.98062</td>\n",
       "      <td>{'learning_rate': 0.01, 'min_child_weight': 3, 'n_estimators': 1000, 'scale_pos_weight': 20}</td>\n",
       "      <td>0.98284</td>\n",
       "      <td>0.00441</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.89984</td>\n",
       "      <td>{'learning_rate': 0.01, 'min_child_weight': 3, 'n_estimators': 1000, 'scale_pos_weight': 30}</td>\n",
       "      <td>0.98253</td>\n",
       "      <td>0.00313</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.88866</td>\n",
       "      <td>{'learning_rate': 0.01, 'min_child_weight': 3, 'n_estimators': 1000, 'scale_pos_weight': 15}</td>\n",
       "      <td>0.98232</td>\n",
       "      <td>0.00319</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.89455</td>\n",
       "      <td>{'learning_rate': 0.01, 'min_child_weight': 3, 'n_estimators': 1000, 'scale_pos_weight': 35}</td>\n",
       "      <td>0.98197</td>\n",
       "      <td>0.00357</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_score_time  \\\n",
       "0          3.51106   \n",
       "3          3.94457   \n",
       "2          4.98062   \n",
       "4          2.89984   \n",
       "1          4.88866   \n",
       "5          2.89455   \n",
       "\n",
       "                                                                                         params  \\\n",
       "0  {'learning_rate': 0.01, 'min_child_weight': 3, 'n_estimators': 1000, 'scale_pos_weight': 10}   \n",
       "3  {'learning_rate': 0.01, 'min_child_weight': 3, 'n_estimators': 1000, 'scale_pos_weight': 25}   \n",
       "2  {'learning_rate': 0.01, 'min_child_weight': 3, 'n_estimators': 1000, 'scale_pos_weight': 20}   \n",
       "4  {'learning_rate': 0.01, 'min_child_weight': 3, 'n_estimators': 1000, 'scale_pos_weight': 30}   \n",
       "1  {'learning_rate': 0.01, 'min_child_weight': 3, 'n_estimators': 1000, 'scale_pos_weight': 15}   \n",
       "5  {'learning_rate': 0.01, 'min_child_weight': 3, 'n_estimators': 1000, 'scale_pos_weight': 35}   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0          0.98358         0.00256                1  \n",
       "3          0.98357         0.00354                2  \n",
       "2          0.98284         0.00441                3  \n",
       "4          0.98253         0.00313                4  \n",
       "1          0.98232         0.00319                5  \n",
       "5          0.98197         0.00357                6  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs_fit_1.cv_results_)[['mean_score_time', 'params', 'mean_test_score', 'std_test_score', 'rank_test_score']].sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71069\n",
      "           1       0.91      0.80      0.85       133\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.95      0.90      0.93     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier(learning_rate=0.01, \n",
    "                            min_child_weight=3,\n",
    "                            n_estimators=1000,\n",
    "                            scale_pos_weight=10,\n",
    "                            n_jobs=-1,\n",
    "                            random_state=11)\n",
    "\n",
    "xgb_clf.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "predictions = xgb_clf.predict(X_test)\n",
    "\n",
    "print(\"Result: \\n\", classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-b354b7463a01>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-13-b354b7463a01>\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    xgb.train(param, dtrain, num_boost_round=1000, evals=[(dtest, 'test'), early_stopping_rounds=20])\u001b[0m\n\u001b[1;37m                                                                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "param = {'learning_rate':0.01, \n",
    "        'min_child_weight':3,\n",
    "        'scale_pos_weight':10,\n",
    "        'n_jobs':-1,\n",
    "        'random_state':11,\n",
    "        'eval_metric':['auc']}\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "xgb.train(param, dtrain, num_boost_round=1000, evals=[(dtest, 'test'), early_stopping_rounds=20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result Roc-Auc score: 0.9022\n"
     ]
    }
   ],
   "source": [
    "print(\"Result Roc-Auc score: {}\".format(round(roc_auc_score(y_test, predictions), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb_clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0971aa8cb54d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtrain_predprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtest_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest_predprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xgb_clf' is not defined"
     ]
    }
   ],
   "source": [
    "train_predictions = xgb_clf.predict(X_train)\n",
    "train_predprob = xgb_clf.predict_proba(X_train)[:,1]\n",
    "\n",
    "test_predictions = xgb_clf.predict(X_test)\n",
    "test_predprob = xgb_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "model_result_train = pd.concat([y_train,\n",
    "                               pd.DataFrame({'predicted_proba':train_predprob}, index = y_train.index),\n",
    "                               pd.DataFrame({'predicted_target':train_predictions}, index = y_train.index),\n",
    "                               pd.DataFrame({'percentile':pd.qcut(train_predprob, 10, labels=False)}, index = y_train.index),\n",
    "                               pd.DataFrame({'set':['train']}, index = y_train.index)], axis=1)\n",
    "\n",
    "model_result_test = pd.concat([y_test,\n",
    "                               pd.DataFrame({'predicted_proba':test_predprob}),\n",
    "                               pd.DataFrame({'predicted_target':test_predictions}),\n",
    "                               pd.DataFrame({'percentile':pd.qcut(test_predprob, 10, labels=False)}),\n",
    "                               pd.DataFrame({'set':['test']})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">predicted_proba</th>\n",
       "      <th>Class</th>\n",
       "      <th>predicted_target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>sum</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentile</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>7123</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>7118</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>7120</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>7120</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>7120</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>7120</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>7120</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>7121</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>7119</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>7121</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.999411</td>\n",
       "      <td>11.0</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           predicted_proba                     Class predicted_target\n",
       "                     count       min       max   sum              sum\n",
       "percentile                                                           \n",
       "0.0                   7123  0.000031  0.000049   3.0              0.0\n",
       "1.0                   7118  0.000049  0.000058   5.0              0.0\n",
       "2.0                   7120  0.000058  0.000071   4.0              0.0\n",
       "3.0                   7120  0.000071  0.000087   3.0              0.0\n",
       "4.0                   7120  0.000087  0.000101   7.0              0.0\n",
       "5.0                   7120  0.000101  0.000123   5.0              0.0\n",
       "6.0                   7120  0.000123  0.000164   6.0              0.0\n",
       "7.0                   7121  0.000164  0.000264   7.0              0.0\n",
       "8.0                   7119  0.000265  0.000592   4.0              0.0\n",
       "9.0                   7121  0.000592  0.999411  11.0            118.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_test = pd.DataFrame(model_result_test.groupby('percentile', sort=True).agg({'predicted_proba':['count','min', 'max'],\n",
    "                                              'Class':'sum',\n",
    "                                              'predicted_target':'sum',\n",
    "                                              }))\n",
    "r_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">predicted_proba</th>\n",
       "      <th>Class</th>\n",
       "      <th>predicted_target</th>\n",
       "      <th>cumulativePct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>sum</th>\n",
       "      <th>sum</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentile</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>7123</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>7118</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>7120</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>7120</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>7120</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>7120</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>7120</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>0.00016</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>7121</td>\n",
       "      <td>0.00016</td>\n",
       "      <td>0.00026</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>7119</td>\n",
       "      <td>0.00026</td>\n",
       "      <td>0.00059</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>7121</td>\n",
       "      <td>0.00059</td>\n",
       "      <td>0.99941</td>\n",
       "      <td>11.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>214.54545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           predicted_proba                   Class predicted_target  \\\n",
       "                     count      min      max   sum              sum   \n",
       "percentile                                                            \n",
       "0.0                   7123  0.00003  0.00005   3.0              0.0   \n",
       "1.0                   7118  0.00005  0.00006   5.0              0.0   \n",
       "2.0                   7120  0.00006  0.00007   4.0              0.0   \n",
       "3.0                   7120  0.00007  0.00009   3.0              0.0   \n",
       "4.0                   7120  0.00009  0.00010   7.0              0.0   \n",
       "5.0                   7120  0.00010  0.00012   5.0              0.0   \n",
       "6.0                   7120  0.00012  0.00016   6.0              0.0   \n",
       "7.0                   7121  0.00016  0.00026   7.0              0.0   \n",
       "8.0                   7119  0.00026  0.00059   4.0              0.0   \n",
       "9.0                   7121  0.00059  0.99941  11.0            118.0   \n",
       "\n",
       "           cumulativePct  \n",
       "                          \n",
       "percentile                \n",
       "0.0              0.00000  \n",
       "1.0              0.00000  \n",
       "2.0              0.00000  \n",
       "3.0              0.00000  \n",
       "4.0              0.00000  \n",
       "5.0              0.00000  \n",
       "6.0              0.00000  \n",
       "7.0              0.00000  \n",
       "8.0              0.00000  \n",
       "9.0            214.54545  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_test['cumulativePct'] = (r_test['predicted_target']['sum'].cumsum() / r_test['Class']['sum'].sum()) * 100\n",
    "r_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">predicted_proba</th>\n",
       "      <th>Class</th>\n",
       "      <th>predicted_target</th>\n",
       "      <th>cumPctRealization</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>sum</th>\n",
       "      <th>sum</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentile</th>\n",
       "      <th>set</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>train</th>\n",
       "      <td>21361</td>\n",
       "      <td>0.00058</td>\n",
       "      <td>0.99943</td>\n",
       "      <td>359</td>\n",
       "      <td>370</td>\n",
       "      <td>1.73213</td>\n",
       "      <td>103061.65442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>train</th>\n",
       "      <td>21360</td>\n",
       "      <td>0.00026</td>\n",
       "      <td>0.00058</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.86608</td>\n",
       "      <td>154593.68784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>train</th>\n",
       "      <td>21361</td>\n",
       "      <td>0.00016</td>\n",
       "      <td>0.00026</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.57739</td>\n",
       "      <td>188948.10874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>train</th>\n",
       "      <td>21360</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>0.00016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.43304</td>\n",
       "      <td>214714.12545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>train</th>\n",
       "      <td>21360</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.34644</td>\n",
       "      <td>235327.03533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>train</th>\n",
       "      <td>21361</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.28869</td>\n",
       "      <td>252504.37980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>train</th>\n",
       "      <td>21359</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24746</td>\n",
       "      <td>267227.96563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>train</th>\n",
       "      <td>21362</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.21652</td>\n",
       "      <td>280110.97398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>train</th>\n",
       "      <td>21360</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.19246</td>\n",
       "      <td>291562.56675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>train</th>\n",
       "      <td>21361</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.17322</td>\n",
       "      <td>301868.97344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 predicted_proba                   Class predicted_target  \\\n",
       "                           count      min      max   sum              sum   \n",
       "percentile set                                                              \n",
       "9          train           21361  0.00058  0.99943   359              370   \n",
       "8          train           21360  0.00026  0.00058     0                0   \n",
       "7          train           21361  0.00016  0.00026     0                0   \n",
       "6          train           21360  0.00012  0.00016     0                0   \n",
       "5          train           21360  0.00010  0.00012     0                0   \n",
       "4          train           21361  0.00009  0.00010     0                0   \n",
       "3          train           21359  0.00007  0.00009     0                0   \n",
       "2          train           21362  0.00006  0.00007     0                0   \n",
       "1          train           21360  0.00005  0.00006     0                0   \n",
       "0          train           21361  0.00003  0.00005     0                0   \n",
       "\n",
       "                 cumPctRealization          lift  \n",
       "                                                  \n",
       "percentile set                                    \n",
       "9          train           1.73213  103061.65442  \n",
       "8          train           0.86608  154593.68784  \n",
       "7          train           0.57739  188948.10874  \n",
       "6          train           0.43304  214714.12545  \n",
       "5          train           0.34644  235327.03533  \n",
       "4          train           0.28869  252504.37980  \n",
       "3          train           0.24746  267227.96563  \n",
       "2          train           0.21652  280110.97398  \n",
       "1          train           0.19246  291562.56675  \n",
       "0          train           0.17322  301868.97344  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_train = pd.DataFrame(model_result_train.groupby(['percentile','set'], sort=True).agg({'predicted_proba':['count','min', 'max'],\n",
    "                                                                              'Class':'sum',\n",
    "                                                                              'predicted_target':'sum',\n",
    "                                                                              })).sort_values('percentile', ascending=False)\n",
    "r_train['cumPctRealization'] = (r_train['predicted_target']['sum'].cumsum() / r_train['predicted_proba']['count'].cumsum()) * 100\n",
    "r_train['lift'] = (r_train['cumPctRealization'].cumsum() / (r_train['Class']['sum'].sum()/r_train['predicted_proba']['count'].sum())) * 100\n",
    "r_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0016806722689075631"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_train['Class']['sum'].sum()/r_train['predicted_proba']['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0306406685236769"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "370/359"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "plt.bar(X_test.columns, xgb_clf.feature_importances_)\n",
    "plt.xlabel(\"Predictors\")\n",
    "plt.ylabel(\"Feature importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh = 0.010487450286746025 | n = 28 | AucScore = 90.97181527599409\n",
      "Thresh = 0.011766676791012287 | n = 27 | AucScore = 90.59657896799858\n",
      "Thresh = 0.013206569477915764 | n = 26 | AucScore = 90.59517188474146\n",
      "Thresh = 0.01541354414075613 | n = 25 | AucScore = 90.59587542637003\n",
      "Thresh = 0.015521185472607613 | n = 24 | AucScore = 90.22204620163164\n",
      "Thresh = 0.016290700063109398 | n = 23 | AucScore = 90.97181527599409\n",
      "Thresh = 0.016370026394724846 | n = 22 | AucScore = 90.59587542637003\n",
      "Thresh = 0.016803910955786705 | n = 21 | AucScore = 90.21993557674597\n",
      "Thresh = 0.01686994545161724 | n = 20 | AucScore = 90.21923203511741\n",
      "Thresh = 0.018024500459432602 | n = 19 | AucScore = 90.21852849348885\n",
      "Thresh = 0.018358560279011726 | n = 18 | AucScore = 90.21712141023174\n",
      "Thresh = 0.018420139327645302 | n = 17 | AucScore = 89.46664879424074\n",
      "Thresh = 0.01853700540959835 | n = 16 | AucScore = 89.83977447735056\n",
      "Thresh = 0.01868893764913082 | n = 15 | AucScore = 90.21219661883183\n",
      "Thresh = 0.01900598406791687 | n = 14 | AucScore = 90.21290016046038\n",
      "Thresh = 0.019017135724425316 | n = 13 | AucScore = 90.21290016046038\n",
      "Thresh = 0.019359339028596878 | n = 12 | AucScore = 90.5881364684559\n",
      "Thresh = 0.021565459668636322 | n = 11 | AucScore = 90.21149307720327\n",
      "Thresh = 0.021624479442834854 | n = 10 | AucScore = 89.8341461443221\n",
      "Thresh = 0.02248966135084629 | n = 9 | AucScore = 89.83696031083633\n",
      "Thresh = 0.02286417968571186 | n = 8 | AucScore = 90.21149307720327\n",
      "Thresh = 0.02357582002878189 | n = 7 | AucScore = 90.9598550683086\n",
      "Thresh = 0.023802731186151505 | n = 6 | AucScore = 91.33720200118978\n",
      "Thresh = 0.02397439256310463 | n = 5 | AucScore = 91.33860908444689\n",
      "Thresh = 0.025201749056577682 | n = 4 | AucScore = 91.71454893407096\n",
      "Thresh = 0.06642838567495346 | n = 3 | AucScore = 91.3315736681613\n",
      "Thresh = 0.08968781679868698 | n = 2 | AucScore = 88.64230430725112\n",
      "Thresh = 0.3766436278820038 | n = 1 | AucScore = 89.33508650970036\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "thresholds = np.sort(xgb_clf.feature_importances_)\n",
    "for thresh in thresholds:\n",
    "    # select features using threshold\n",
    "    selection = SelectFromModel(xgb_clf, threshold=thresh, prefit=True)\n",
    "    select_X_train = selection.transform(X_train)\n",
    "    \n",
    "    # train model\n",
    "    selection_model = xgb.XGBClassifier(learning_rate=0.01, \n",
    "                                        min_child_weight=3,\n",
    "                                        n_estimators=1000,\n",
    "                                        scale_pos_weight=10,\n",
    "                                        tree_method='hist',\n",
    "                                        n_jobs=-1,\n",
    "                                        random_state=11)\n",
    "    selection_model.fit(select_X_train, y_train)\n",
    "    \n",
    "    # evaluate model\n",
    "    select_X_test = selection.transform(X_test)\n",
    "    predictions = selection_model.predict(select_X_test)\n",
    "    \n",
    "    auc_score = roc_auc_score(y_test, predictions)\n",
    "    \n",
    "    print(\"Thresh = {} | n = {} | AucScore = {}\".format(thresh, select_X_train.shape[1], auc_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = pd.DataFrame({'Predictors':list(X_test.columns), 'Feature Importance': list(xgb_clf.feature_importances_)})\n",
    "feat_imp['pct_rank'] = feat_imp['Feature Importance'].rank(pct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = feat_imp.sort_values('pct_rank').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp['pct_rank_numb'] = pd.qcut(feat_imp['pct_rank'], 10, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Predictors</th>\n",
       "      <th>Feature Importance</th>\n",
       "      <th>pct_rank</th>\n",
       "      <th>pct_rank_numb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>V23</td>\n",
       "      <td>0.01049</td>\n",
       "      <td>0.03571</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>V24</td>\n",
       "      <td>0.01177</td>\n",
       "      <td>0.07143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>V5</td>\n",
       "      <td>0.01321</td>\n",
       "      <td>0.10714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>V26</td>\n",
       "      <td>0.01541</td>\n",
       "      <td>0.14286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>V20</td>\n",
       "      <td>0.01552</td>\n",
       "      <td>0.17857</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>V9</td>\n",
       "      <td>0.01629</td>\n",
       "      <td>0.21429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27</td>\n",
       "      <td>V28</td>\n",
       "      <td>0.01637</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>V18</td>\n",
       "      <td>0.01680</td>\n",
       "      <td>0.28571</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>V16</td>\n",
       "      <td>0.01687</td>\n",
       "      <td>0.32143</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>V2</td>\n",
       "      <td>0.01802</td>\n",
       "      <td>0.35714</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18</td>\n",
       "      <td>V19</td>\n",
       "      <td>0.01836</td>\n",
       "      <td>0.39286</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>V15</td>\n",
       "      <td>0.01842</td>\n",
       "      <td>0.42857</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>26</td>\n",
       "      <td>V27</td>\n",
       "      <td>0.01854</td>\n",
       "      <td>0.46429</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21</td>\n",
       "      <td>V22</td>\n",
       "      <td>0.01869</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>V3</td>\n",
       "      <td>0.01901</td>\n",
       "      <td>0.53571</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11</td>\n",
       "      <td>V12</td>\n",
       "      <td>0.01902</td>\n",
       "      <td>0.57143</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>24</td>\n",
       "      <td>V25</td>\n",
       "      <td>0.01936</td>\n",
       "      <td>0.60714</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>V8</td>\n",
       "      <td>0.02157</td>\n",
       "      <td>0.64286</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>V1</td>\n",
       "      <td>0.02162</td>\n",
       "      <td>0.67857</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>V6</td>\n",
       "      <td>0.02249</td>\n",
       "      <td>0.71429</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>V21</td>\n",
       "      <td>0.02286</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10</td>\n",
       "      <td>V11</td>\n",
       "      <td>0.02358</td>\n",
       "      <td>0.78571</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>V7</td>\n",
       "      <td>0.02380</td>\n",
       "      <td>0.82143</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12</td>\n",
       "      <td>V13</td>\n",
       "      <td>0.02397</td>\n",
       "      <td>0.85714</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>V4</td>\n",
       "      <td>0.02520</td>\n",
       "      <td>0.89286</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9</td>\n",
       "      <td>V10</td>\n",
       "      <td>0.06643</td>\n",
       "      <td>0.92857</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>16</td>\n",
       "      <td>V17</td>\n",
       "      <td>0.08969</td>\n",
       "      <td>0.96429</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13</td>\n",
       "      <td>V14</td>\n",
       "      <td>0.37664</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index Predictors  Feature Importance  pct_rank  pct_rank_numb\n",
       "0      22        V23             0.01049   0.03571              0\n",
       "1      23        V24             0.01177   0.07143              0\n",
       "2       4         V5             0.01321   0.10714              0\n",
       "3      25        V26             0.01541   0.14286              1\n",
       "4      19        V20             0.01552   0.17857              1\n",
       "5       8         V9             0.01629   0.21429              1\n",
       "6      27        V28             0.01637   0.25000              2\n",
       "7      17        V18             0.01680   0.28571              2\n",
       "8      15        V16             0.01687   0.32143              2\n",
       "9       1         V2             0.01802   0.35714              3\n",
       "10     18        V19             0.01836   0.39286              3\n",
       "11     14        V15             0.01842   0.42857              4\n",
       "12     26        V27             0.01854   0.46429              4\n",
       "13     21        V22             0.01869   0.50000              4\n",
       "14      2         V3             0.01901   0.53571              5\n",
       "15     11        V12             0.01902   0.57143              5\n",
       "16     24        V25             0.01936   0.60714              5\n",
       "17      7         V8             0.02157   0.64286              6\n",
       "18      0         V1             0.02162   0.67857              6\n",
       "19      5         V6             0.02249   0.71429              7\n",
       "20     20        V21             0.02286   0.75000              7\n",
       "21     10        V11             0.02358   0.78571              7\n",
       "22      6         V7             0.02380   0.82143              8\n",
       "23     12        V13             0.02397   0.85714              8\n",
       "24      3         V4             0.02520   0.89286              8\n",
       "25      9        V10             0.06643   0.92857              9\n",
       "26     16        V17             0.08969   0.96429              9\n",
       "27     13        V14             0.37664   1.00000              9"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pct_rank_numb\n",
       "0    0.10714\n",
       "1    0.21429\n",
       "2    0.32143\n",
       "3    0.39286\n",
       "4    0.50000\n",
       "5    0.60714\n",
       "6    0.67857\n",
       "7    0.78571\n",
       "8    0.89286\n",
       "9    1.00000\n",
       "Name: pct_rank, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp = feat_imp.drop(columns=['prc_rank_numb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Predictors</th>\n",
       "      <th>Feature Importance</th>\n",
       "      <th>pct_rank</th>\n",
       "      <th>pct_rank_numb</th>\n",
       "      <th>pct_rank_max</th>\n",
       "      <th>pct_rank_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>V23</td>\n",
       "      <td>0.01049</td>\n",
       "      <td>0.03571</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10714</td>\n",
       "      <td>0.03571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>V24</td>\n",
       "      <td>0.01177</td>\n",
       "      <td>0.07143</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10714</td>\n",
       "      <td>0.03571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>V5</td>\n",
       "      <td>0.01321</td>\n",
       "      <td>0.10714</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10714</td>\n",
       "      <td>0.03571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>V26</td>\n",
       "      <td>0.01541</td>\n",
       "      <td>0.14286</td>\n",
       "      <td>1</td>\n",
       "      <td>0.21429</td>\n",
       "      <td>0.14286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>V20</td>\n",
       "      <td>0.01552</td>\n",
       "      <td>0.17857</td>\n",
       "      <td>1</td>\n",
       "      <td>0.21429</td>\n",
       "      <td>0.14286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index Predictors  Feature Importance  pct_rank  pct_rank_numb  \\\n",
       "0     22        V23             0.01049   0.03571              0   \n",
       "1     23        V24             0.01177   0.07143              0   \n",
       "2      4         V5             0.01321   0.10714              0   \n",
       "3     25        V26             0.01541   0.14286              1   \n",
       "4     19        V20             0.01552   0.17857              1   \n",
       "\n",
       "   pct_rank_max  pct_rank_min  \n",
       "0       0.10714       0.03571  \n",
       "1       0.10714       0.03571  \n",
       "2       0.10714       0.03571  \n",
       "3       0.21429       0.14286  \n",
       "4       0.21429       0.14286  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_max_min_pct = pd.DataFrame({'pct_rank_max':feat_imp.groupby('pct_rank_numb')['pct_rank'].max(),\n",
    "                               'pct_rank_min':feat_imp.groupby('pct_rank_numb')['pct_rank'].min()})\n",
    "feat_imp = pd.merge(feat_imp, df_max_min_pct, on=['pct_rank_numb'])\n",
    "feat_imp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "Thresh = []\n",
    "n_items = []\n",
    "aucScore = []\n",
    "\n",
    "thresholds = np.sort(xgb_clf.feature_importances_)\n",
    "for thresh in thresholds:\n",
    "    # select features using threshold\n",
    "    selection = SelectFromModel(xgb_clf, threshold=thresh, prefit=True)\n",
    "    select_X_train = selection.transform(X_train)\n",
    "    \n",
    "    # train model\n",
    "    selection_model = xgb.XGBClassifier(learning_rate=0.01, \n",
    "                                        min_child_weight=3,\n",
    "                                        n_estimators=1000,\n",
    "                                        scale_pos_weight=10,\n",
    "                                        tree_method='hist',\n",
    "                                        n_jobs=-1,\n",
    "                                        random_state=11)\n",
    "    selection_model.fit(select_X_train, y_train)\n",
    "    \n",
    "    # evaluate model\n",
    "    select_X_test = selection.transform(X_test)\n",
    "    predictions = selection_model.predict(select_X_test)\n",
    "    \n",
    "    auc_score = roc_auc_score(y_test, predictions)\n",
    "    \n",
    "    #print(\"Thresh = {} | n = {} | AucScore = {}\".format(thresh, select_X_train.shape[1], auc_score*100))\n",
    "    \n",
    "    Thresh.append(thresh)\n",
    "    n_items.append(select_X_train.shape[1])\n",
    "    aucScore.append(auc_score*100)\n",
    "    \n",
    "result = pd.DataFrame({'Thresh': Thresh, 'n': n_items, 'Auc Score':aucScore})    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Thresh</th>\n",
       "      <th>n</th>\n",
       "      <th>Auc Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.02520</td>\n",
       "      <td>4</td>\n",
       "      <td>91.71455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.02397</td>\n",
       "      <td>5</td>\n",
       "      <td>91.33861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.02380</td>\n",
       "      <td>6</td>\n",
       "      <td>91.33720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.06643</td>\n",
       "      <td>3</td>\n",
       "      <td>91.33157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01049</td>\n",
       "      <td>28</td>\n",
       "      <td>90.97182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Thresh   n  Auc Score\n",
       "24  0.02520   4   91.71455\n",
       "23  0.02397   5   91.33861\n",
       "22  0.02380   6   91.33720\n",
       "25  0.06643   3   91.33157\n",
       "0   0.01049  28   90.97182"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sort_values('Auc Score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
